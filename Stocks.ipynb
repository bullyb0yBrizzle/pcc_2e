{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stocks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPajpDHKUJUvjCWcXp76zXp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bullyb0yBrizzle/pcc_2e/blob/master/Stocks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aiq8Si5CwWxf"
      },
      "source": [
        "#Description: This program optimizes a stock portfoliio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hHp5tv70Jfg"
      },
      "source": [
        "#@title\n",
        "#Import the python libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "#If package does not exist then you can install by using \"!\"\n",
        "#! = run a command line\n",
        "!pip install yfinance\n",
        "import yfinance as yf\n",
        "from bs4 import BeautifulSoup\n",
        "import lxml\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEAIuIEhJTXC"
      },
      "source": [
        "#Start process with basic search URL\r\n",
        "search_url = f'https://www.londonstockexchange.com/live-markets/market-data-dashboard/price-explorer?markets=AIM&lang=en' \r\n",
        "#Add a base URL if there is more than one page and we need to loop\r\n",
        "base_url = f'https://www.londonstockexchange.com/live-markets/market-data-dashboard/price-explorer?markets=AIM&lang=en&page=' \r\n",
        "\r\n",
        "# HTTP GET requests\r\n",
        "page = requests.get(search_url)\r\n",
        "\r\n",
        "#Create a dictionary to hold all stock codes\r\n",
        "allstocks = []\r\n",
        "print(allstocks)\r\n",
        "#From the first page we need to get href that holds the total page count to \r\n",
        "#cycle through\r\n",
        "\r\n",
        "if page.status_code == requests.codes.ok:\r\n",
        "  bs = BeautifulSoup(page.text, 'lxml')\r\n",
        "  page_href = bs.findAll('a',{\"page-number page-last\"})\r\n",
        "  for a in page_href:\r\n",
        "    page_href_string = (a['href'])\r\n",
        "    newpagehref=page_href_string.replace('page=','*')\r\n",
        "    startcount=newpagehref.find('*')\r\n",
        "    pagecount=newpagehref[startcount+1:]\r\n",
        "\r\n",
        "#Now let's create a list of and populate with a range of page numbers using the \r\n",
        "#max value from above\r\n",
        "\r\n",
        "pages = list(range(1,int(pagecount)+1,1))\r\n",
        "print(pages)\r\n",
        "\r\n",
        "#Now we begin searching through pages in loop\r\n",
        "\r\n",
        "\r\n",
        "#Testing Code for  now\r\n",
        "#Checking if we successfully fetched the URL\r\n",
        "# if page.status_code == requests.codes.ok:\r\n",
        "#   bs = BeautifulSoup(page.text, 'lxml')\r\n",
        "#   las_aref = bs.findAll('a',{\"class\":'dash-link blue-text'})  \r\n",
        "#   for a in las_aref:\r\n",
        "#     href=(a['href'])\r\n",
        "#     newhref=href.replace('stock/','')\r\n",
        "#     seppo=newhref.find('/')\r\n",
        "#     scode = newhref[0:seppo]\r\n",
        "#     sname = newhref[seppo+1:]\r\n",
        "#     print(f\"added {scode}:{sname} to dictionary\")\r\n",
        "#     thisdict = {\"name\":sname,\"code\":scode,\"closing_prices\":{}}\r\n",
        "#     allstocks.append(thisdict)\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "for p in pages:\r\n",
        "  page = requests.get(base_url+str(p))\r\n",
        "  #Checking if we successfully fetched the URL\r\n",
        "  if page.status_code == requests.codes.ok:\r\n",
        "    bs = BeautifulSoup(page.text, 'lxml')\r\n",
        "    las_aref = bs.findAll('a',{\"class\":'dash-link blue-text'})  \r\n",
        "    for a in las_aref:\r\n",
        "      href=(a['href'])\r\n",
        "      newhref=href.replace('stock/','')\r\n",
        "      seppo=newhref.find('/')\r\n",
        "      scode = newhref[0:seppo]\r\n",
        "      sname = newhref[seppo+1:]\r\n",
        "      print(f\"added {scode}:{sname} to dictionary\")\r\n",
        "      thisdict = {\"name\":sname,\"code\":scode,\"closing_prices\":{}}\r\n",
        "      allstocks.append(thisdict)\r\n",
        "# print(stocks)\r\n",
        "\r\n",
        "\r\n",
        "print(allstocks)\r\n",
        "  \r\n",
        "#<a _ngcontent-ng-lseg-c19=\"\" class=\"page-number page-last\" rel=\"nofollow\" title=\"Go to last page\" href=\"/live-markets/market-data-dashboard/price-explorer?markets=AIM&amp;lang=en&amp;page=42\">Last page</a>\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUFlIcLx0f2y"
      },
      "source": [
        "for s in allstocks:\r\n",
        "  mycode=s.get('code')\r\n",
        "  #Now we have code, lets get data on it\r\n",
        "  data = yf.download(mycode, start=\"2010-01-01\", end=\"2021-02-11\")\r\n",
        "  data.head() \r\n",
        "\r\n",
        "#print(allstocks)\r\n",
        "# #Load the data\r\n",
        "# #from google.colab import files\r\n",
        "# #files.upload()\r\n",
        "\r\n",
        "# data = yf.download(\"SPY AAPL\", start=\"2017-01-01\", end=\"2017-04-30\")\r\n",
        "\r\n",
        "# #tsla_df = yf.download('TSLA', \r\n",
        "# #                      start='2019-01-01', \r\n",
        "# #                      end='2019-12-31', \r\n",
        "# #                      progress=False)\r\n",
        "# #tsla_df.head()\r\n",
        "\r\n",
        "# data.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}